{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, \"rb\")\n",
    "    for line in g:\n",
    "        yield eval(line)\n",
    "\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(filePath):\n",
    "    # data = []\n",
    "    # ratings = pd.read_csv(filePath, delimiter=\",\", encoding=\"latin1\")\n",
    "    ratings = getDF(filePath)\n",
    "    ratings = ratings[[\"reviewerID\", \"asin\", \"overall\", \"unixReviewTime\"]]\n",
    "\n",
    "    ratings.columns = [\"userId\", \"itemId\", \"Rating\", \"timestamp\"]\n",
    "    ratings = ratings.loc[ratings[\"Rating\"] >= 3.0]\n",
    "    ratings = ratings.drop_duplicates()\n",
    "\n",
    "    rate_size_dic_i = ratings.groupby(\"itemId\").size()\n",
    "    choosed_index_del_i = rate_size_dic_i.index[rate_size_dic_i < 5]\n",
    "    ratings = ratings[~ratings[\"itemId\"].isin(list(choosed_index_del_i))]  # item freq more than 10\n",
    "\n",
    "    user_unique = list(ratings[\"userId\"].unique())\n",
    "    movie_unique = list(ratings[\"itemId\"].unique())\n",
    "\n",
    "    u = len(user_unique)\n",
    "    i = len(movie_unique)\n",
    "\n",
    "    rating_num = len(ratings)\n",
    "    return u, i, rating_num, user_unique, ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_user(ratings1, ratings2):\n",
    "    rate_size_dic_u1 = ratings1.groupby(\"userId\").size()\n",
    "    rate_size_dic_u2 = ratings2.groupby(\"userId\").size()\n",
    "    choosed_index_del_u1 = rate_size_dic_u1.index[rate_size_dic_u1 < 60]\n",
    "    choosed_index_del_u2 = rate_size_dic_u2.index[rate_size_dic_u2 < 60]\n",
    "    ratings1 = ratings1[~ratings1[\"userId\"].isin(list(choosed_index_del_u1) + list(choosed_index_del_u2))]\n",
    "    ratings2 = ratings2[~ratings2[\"userId\"].isin(list(choosed_index_del_u2) + list(choosed_index_del_u2))]\n",
    "    return ratings1, ratings2\n",
    "\n",
    "\n",
    "def filter_item(ratings1, ratings2):\n",
    "    rate_size_dic_u1 = ratings1.groupby(\"itemId\").size()\n",
    "    rate_size_dic_u2 = ratings2.groupby(\"itemId\").size()\n",
    "    choosed_index_del_u1 = rate_size_dic_u1.index[rate_size_dic_u1 < 20]\n",
    "    choosed_index_del_u2 = rate_size_dic_u2.index[rate_size_dic_u2 < 20]\n",
    "    ratings1 = ratings1[~ratings1[\"itemId\"].isin(list(choosed_index_del_u1) + list(choosed_index_del_u2))]\n",
    "    ratings2 = ratings2[~ratings2[\"itemId\"].isin(list(choosed_index_del_u1) + list(choosed_index_del_u2))]\n",
    "    return ratings1, ratings2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(ratings1, ratings2, ratio1, ratio2):\n",
    "    overlap_user = list(set(list(ratings1[\"userId\"].unique())) & set(list(ratings2[\"userId\"].unique())))\n",
    "    non_overlap_ratings1 = ratings1[~ratings1[\"userId\"].isin(overlap_user)]\n",
    "    non_overlap_ratings2 = ratings2[~ratings2[\"userId\"].isin(overlap_user)]\n",
    "\n",
    "    ratings1_nolap_user = list(non_overlap_ratings1[\"userId\"].unique())\n",
    "    ratings2_nolap_user = list(non_overlap_ratings2[\"userId\"].unique())\n",
    "\n",
    "    samples1 = int(ratio1 * len(ratings1_nolap_user))\n",
    "    samples2 = int(ratio2 * len(ratings2_nolap_user))\n",
    "\n",
    "    sampled_user1 = random.sample(ratings1_nolap_user, samples1)\n",
    "    sampled_user2 = random.sample(ratings2_nolap_user, samples2)\n",
    "\n",
    "    new_ratings1 = ratings1[ratings1[\"userId\"].isin(overlap_user + sampled_user1)]\n",
    "    new_ratings2 = ratings2[ratings2[\"userId\"].isin(overlap_user + sampled_user2)]\n",
    "\n",
    "    return new_ratings1, new_ratings2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_csv = \"amazon14/reviews_Movies_and_TV_5.json.gz\"\n",
    "data2_csv = \"amazon14/reviews_Digital_Music_5.json.gz\"\n",
    "data3_csv = \"amazon14/reviews_Books_5.json.gz\"\n",
    "\n",
    "u, i, rating_num, user_unique1, ratings1 = filter_data(data1_csv)\n",
    "print(u, i, rating_num)\n",
    "u, i, rating_num, user_unique2, ratings2 = filter_data(data2_csv)\n",
    "print(u, i, rating_num)\n",
    "u, i, rating_num, user_unique3, ratings3 = filter_data(data3_csv)\n",
    "print(u, i, rating_num)\n",
    "\n",
    "overlap_user = list(set(user_unique1) & set(user_unique2) & set(user_unique3))\n",
    "\n",
    "new_ratings1 = ratings1[ratings1[\"userId\"].isin(overlap_user)]\n",
    "new_ratings2 = ratings2[ratings2[\"userId\"].isin(overlap_user)]\n",
    "new_ratings3 = ratings3[ratings3[\"userId\"].isin(overlap_user)]\n",
    "print(len(overlap_user), len(new_ratings1[\"itemId\"].unique()), len(new_ratings1))\n",
    "print(len(overlap_user), len(new_ratings2[\"itemId\"].unique()), len(new_ratings2))\n",
    "print(len(overlap_user), len(new_ratings3[\"itemId\"].unique()), len(new_ratings3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_inter(ratings, path):\n",
    "    ratings = ratings.rename(\n",
    "        columns={\n",
    "            \"userId\": \"user_id:token\",\n",
    "            \"itemId\": \"item_id:token\",\n",
    "            \"Rating\": \"rating:float\",\n",
    "            \"timestamp\": \"timestamp:float\",\n",
    "        }\n",
    "    )\n",
    "    if not os.path.exists(os.path.dirname(path)):\n",
    "        os.makedirs(os.path.dirname(path))\n",
    "    ratings.to_csv(path, sep=\"\\t\", index=False)\n",
    "    return ratings\n",
    "\n",
    "\n",
    "save_inter(new_ratings1, \"./processed/movie/movie.inter\")\n",
    "save_inter(new_ratings2, \"./processed/music/music.inter\")\n",
    "save_inter(new_ratings3, \"./processed/book/book.inter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./processed/douban/douban.inter\"\n",
    "data_df = pd.read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# music domain 0 movie domain 1 all filter user number :110073, item number :44741\n",
    "source_csv = \"amazon14/reviews_Movies_and_TV_5.json.gz\"\n",
    "target_csv = \"amazon14/reviews_Books_5.json.gz\"\n",
    "\n",
    "u1, i1, rating_num1, user_unique1, ratings1 = filter_data(source_csv)\n",
    "u2, i2, rating_num2, user_unique2, ratings2 = filter_data(target_csv)\n",
    "# save_csv_name = \"music_movie_all.csv\"\n",
    "print(u1, i1, rating_num1)\n",
    "print(u2, i2, rating_num2)\n",
    "print(len(list(set(list(ratings1[\"userId\"].unique())) & set(list(ratings2[\"userId\"].unique())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_ratings1, filter_ratings2 = filter_user(ratings1, ratings2)  # del overlap user < 5\n",
    "filter_ratings1, filter_ratings2 = filter_item(filter_ratings1, filter_ratings2)  # del overlap user < 5\n",
    "\n",
    "# filter_ratings1 = filter_ratings1.loc[filter_ratings1[\"Rating\"] >= 3.0]\n",
    "# filter_ratings2 = filter_ratings2.loc[filter_ratings2[\"Rating\"] >= 3.0]\n",
    "\n",
    "print(\n",
    "    len(list(filter_ratings1[\"userId\"].unique())), len(list(filter_ratings1[\"itemId\"].unique())), len(filter_ratings1)\n",
    ")\n",
    "print(\n",
    "    len(list(filter_ratings2[\"userId\"].unique())), len(list(filter_ratings2[\"itemId\"].unique())), len(filter_ratings2)\n",
    ")\n",
    "print(len(list(set(list(filter_ratings1[\"userId\"].unique())) & set(list(filter_ratings2[\"userId\"].unique())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ratings1, sample_ratings2 = sample_data(filter_ratings1, filter_ratings2, 1.0, 1.0)\n",
    "print(len(sample_ratings1), len(sample_ratings2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ratings1 = sample_ratings1.rename(\n",
    "    columns={\n",
    "        \"userId\": \"user_id:token\",\n",
    "        \"itemId\": \"item_id:token\",\n",
    "        \"Rating\": \"rating:float\",\n",
    "        \"timestamp\": \"timestamp:float\",\n",
    "    }\n",
    ")\n",
    "sample_ratings2 = sample_ratings2.rename(\n",
    "    columns={\n",
    "        \"userId\": \"user_id:token\",\n",
    "        \"itemId\": \"item_id:token\",\n",
    "        \"Rating\": \"rating:float\",\n",
    "        \"timestamp\": \"timestamp:float\",\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "if not os.path.exists(\"./processed/movie\"):\n",
    "    os.makedirs(\"./processed/movie\", exist_ok=True)\n",
    "if not os.path.exists(\"./processed/book\"):\n",
    "    os.makedirs(\"./processed/book\", exist_ok=True)\n",
    "sample_ratings1.to_csv(\"./processed/movie/movie.inter\", sep=\"\\t\", index=False)\n",
    "sample_ratings2.to_csv(\"./processed/book/book.inter\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"./processed/netflix/netflix.inter\", sep=\"\\t\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.columns = [\"userId\", \"itemId\", \"Rating\", \"timestamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.001\n",
    "samples = int(ratio * len(ratings[\"userId\"].unique()))\n",
    "sampled_user = random.sample(list(ratings[\"userId\"].unique()), samples)\n",
    "sampled_ratings = ratings[ratings[\"userId\"].isin(sampled_user)]\n",
    "sampled_ratings.shape\n",
    "# samples1 = int(ratio1 * len(ratings1_nolap_user))\n",
    "# samples2 = int(ratio2 * len(ratings2_nolap_user))\n",
    "\n",
    "# sampled_user1 = random.sample(ratings1_nolap_user, samples1)\n",
    "# sampled_user2 = random.sample(ratings2_nolap_user, samples2)\n",
    "\n",
    "# new_ratings1 = ratings1[ratings1[\"userId\"].isin(overlap_user + sampled_user1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex_ratings(ratings1, ratings2):\n",
    "    user_unique1 = list(ratings1[\"userId\"].unique())\n",
    "    user_unique2 = list(ratings2[\"userId\"].unique())\n",
    "    item_unique1 = list(ratings1[\"itemId\"].unique())\n",
    "    item_unique2 = list(ratings2[\"itemId\"].unique())\n",
    "    user_dict = dict()\n",
    "    item_dict = dict()\n",
    "    for i in range(len(user_unique1)):\n",
    "        user_dict[user_unique1[i]] = i\n",
    "    for i in range(len(user_unique2)):\n",
    "        user_dict[user_unique2[i]] = i + len(user_dict)\n",
    "    for i in range(len(item_unique1)):\n",
    "        item_dict[item_unique1[i]] = i\n",
    "    for i in range(len(item_unique2)):\n",
    "        item_dict[item_unique2[i]] = i + len(item_dict)\n",
    "    ratings1[\"userId\"] = ratings1[\"userId\"].apply(lambda x: user_dict[x])\n",
    "    ratings2[\"userId\"] = ratings2[\"userId\"].apply(lambda x: user_dict[x])\n",
    "    ratings1[\"itemId\"] = ratings1[\"itemId\"].apply(lambda x: item_dict[x])\n",
    "    ratings2[\"itemId\"] = ratings2[\"itemId\"].apply(lambda x: item_dict[x])\n",
    "    print(\"all user number :{}, item number :{}\".format(len(user_dict), len(item_dict)))\n",
    "    return ratings1, ratings2\n",
    "\n",
    "\n",
    "def find_dict(ratings):\n",
    "    seq = defaultdict(list)\n",
    "    uid = ratings[\"userId\"].tolist()\n",
    "    iid = ratings[\"itemId\"].tolist()\n",
    "    for i in range(len(uid)):\n",
    "        seq[uid[i]].append(iid[i])\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings1, ratings2 = reindex_ratings(ratings1, ratings2)\n",
    "# print(ratings1,ratings2)\n",
    "\n",
    "seq1 = find_dict(ratings1)\n",
    "seq2 = find_dict(ratings2)\n",
    "# print(seq1,seq2)\n",
    "user_unique1 = list(ratings1[\"userId\"].unique())\n",
    "user_unique2 = list(ratings2[\"userId\"].unique())\n",
    "user_node, seq_d1, seq_d2, domain_id = [], [], [], []\n",
    "\n",
    "for u_id_tmp in user_unique1:\n",
    "    if len(seq1[u_id_tmp]) >= 5 and (len(seq2[u_id_tmp]) >= 5 or len(seq2[u_id_tmp]) == 0):\n",
    "        user_node.append(u_id_tmp)\n",
    "        seq_d1.append(seq1[u_id_tmp])\n",
    "        seq_d2.append(seq2[u_id_tmp])\n",
    "        domain_id.append(0)\n",
    "\n",
    "for u_id_tmp in user_unique2:\n",
    "    if len(seq2[u_id_tmp]) >= 5 and (len(seq1[u_id_tmp]) >= 5 or len(seq1[u_id_tmp]) == 0):\n",
    "        user_node.append(u_id_tmp)\n",
    "        seq_d1.append(seq1[u_id_tmp])\n",
    "        seq_d2.append(seq2[u_id_tmp])\n",
    "        domain_id.append(1)\n",
    "\n",
    "\n",
    "dataframe = pd.DataFrame({\"user_id\": user_node, \"seq_d1\": seq_d1, \"seq_d2\": seq_d2, \"domain_id\": domain_id})\n",
    "print(len(dataframe))\n",
    "user_unique1 = list(dataframe[\"user_id\"].unique())\n",
    "\n",
    "save_csv_name = \"music_movie_all.csv\"\n",
    "\n",
    "user_dict = dict()\n",
    "for i in range(len(user_unique1)):\n",
    "    user_dict[user_unique1[i]] = i\n",
    "dataframe[\"user_id\"] = dataframe[\"user_id\"].apply(lambda x: user_dict[x])\n",
    "print(dataframe)\n",
    "dataframe.to_csv(save_csv_name, index=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"dataset/ratings_Clothing_Shoes_and_Jewelry.csv\", delimiter=\",\", encoding=\"latin1\")\n",
    "df2 = pd.read_csv(\"dataset/ratings_Sports_and_Outdoors.csv\", delimiter=\",\", encoding=\"latin1\")\n",
    "df1.columns = [\"userId\", \"itemId\", \"Rating\", \"timesteamp\"]\n",
    "df2.columns = [\"userId\", \"itemId\", \"Rating\", \"timesteamp\"]\n",
    "len(list(set(list(df1[\"userId\"].unique())) & set(list(df2[\"userId\"].unique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "data = OrderedDict(\n",
    "    [\n",
    "        (\"0-hit@5\", 0.0043),\n",
    "        (\"0-hit@10\", 0.0072),\n",
    "        (\"0-hit@20\", 0.0187),\n",
    "        (\"0-ndcg@5\", 0.0024),\n",
    "        (\"0-ndcg@10\", 0.0033),\n",
    "        (\"0-ndcg@20\", 0.0062),\n",
    "        (\"0-mrr@5\", 0.0018),\n",
    "        (\"0-mrr@10\", 0.0022),\n",
    "        (\"0-mrr@20\", 0.0029),\n",
    "        (\"0-precision@5\", 0.0009),\n",
    "        (\"0-precision@10\", 0.0007),\n",
    "        (\"0-precision@20\", 0.0009),\n",
    "        (\"0-loss\", 0.004844015357138097),\n",
    "    ]\n",
    ")\n",
    "\n",
    "table = PrettyTable([\"Metric\", \"Value\"])\n",
    "for key, value in data.items():\n",
    "    table.add_row([key, value])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "data_save_path = \"../save/SASRec.music/clusters_20.spc_6.len_50.dim_32/2024-09-20.18-46-07/checkpoints/last-ckpt\"\n",
    "model_save_path = \"../checkpoint/SASRec-music.heads_1.layers_1.hiddens_32.inners_64.maxlen_50.batch_2048.epochs_100.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open(os.path.join(data_save_path, \"config.json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(model_save_path)\n",
    "initial_state_dict = checkpoint[\"state_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"item_emb\"] = initial_state_dict[\"item_embedding.weight\"].cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(config, open(os.path.join(data_save_path, \"config.json\"), \"w\"), indent=4)\n",
    "# torch.save(data_dict(detach=True), os.path.join(save_path, \"data_dict\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>rating:float</th>\n",
       "      <th>timestamp:float</th>\n",
       "      <th>price:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tjtoolmanz</td>\n",
       "      <td>Samsung_226BW_Monitor</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1195516800</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rufster</td>\n",
       "      <td>Samsung_226BW_Monitor</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1181606400</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jdproconsumer</td>\n",
       "      <td>Samsung_226BW_Monitor</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1193443200</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>denverbrian</td>\n",
       "      <td>pr-Minolta_Dimage_X20_Digital_Camera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1099094400</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>endurance</td>\n",
       "      <td>pr-Minolta_Dimage_X20_Digital_Camera</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1096761600</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id:token                         item_id:token  rating:float  \\\n",
       "0     tjtoolmanz                 Samsung_226BW_Monitor           5.0   \n",
       "1        Rufster                 Samsung_226BW_Monitor           5.0   \n",
       "2  jdproconsumer                 Samsung_226BW_Monitor           4.0   \n",
       "3    denverbrian  pr-Minolta_Dimage_X20_Digital_Camera           5.0   \n",
       "4      endurance  pr-Minolta_Dimage_X20_Digital_Camera           4.0   \n",
       "\n",
       "   timestamp:float price:float  \n",
       "0       1195516800       299.0  \n",
       "1       1181606400       300.0  \n",
       "2       1193443200       269.0  \n",
       "3       1099094400       120.0  \n",
       "4       1096761600       100.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from recbole.utils import init_seed\n",
    "\n",
    "seed = 42\n",
    "init_seed(seed, reproducibility=True)\n",
    "\n",
    "data = \"epinions\"\n",
    "\n",
    "df = pd.read_csv(f\"./processed/{data}/{data}.inter\", sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Sample\n",
    "def random_sample(fracs):\n",
    "    for frac in fracs:\n",
    "        sampled_groups = df[\"user_id:token\"].drop_duplicates().sample(frac=frac, random_state=seed)\n",
    "        sampled_df = df[df[\"user_id:token\"].isin(sampled_groups)]\n",
    "        # sampled_df = df.sample(frac=frac, random_state=seed)\n",
    "        os.makedirs(f\"processed/{data}_{frac}\", exist_ok=True)\n",
    "        sampled_df.to_csv(f\"processed/{data}_{frac}/{data}_{frac}.inter\", sep=\"\\t\", index=False)\n",
    "\n",
    "\n",
    "# Longest Sample\n",
    "def longest_sample(fracs):\n",
    "    for frac in fracs:\n",
    "        group_sizes = df.groupby(\"user_id:token\").size().sort_values(ascending=False)\n",
    "        num_groups_to_sample = int(len(group_sizes) * frac)\n",
    "        top_groups = group_sizes.head(num_groups_to_sample)\n",
    "        sampled_df = df[df[\"user_id:token\"].isin(top_groups.index)]\n",
    "        sampled_df.to_csv(f\"processed/{data}_{frac}/{data}_{frac}.inter\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fracs = [0.005, 0.03, 0.1, 0.3, 0.5, 0.8, 1.0]\n",
    "random_sample(fracs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id:token\n",
       "1      272\n",
       "2       62\n",
       "3       54\n",
       "4       24\n",
       "5      175\n",
       "      ... \n",
       "939     49\n",
       "940    107\n",
       "941     22\n",
       "942     79\n",
       "943    168\n",
       "Length: 943, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_size_dic_u = df.groupby(\"user_id:token\").size()\n",
    "rate_size_dic_i = df.groupby(\"item_id:token\").size()\n",
    "rate_size_dic_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choosed_index_del_u = rate_size_dic_u[rate_size_dic_u < 5].index\n",
    "choosed_index_del_i = rate_size_dic_i[rate_size_dic_i < 5].index\n",
    "choosed_index_del_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_df = df[~df[\"item_id:token\"].isin(list(choosed_index_del_i))]\n",
    "core_df = core_df[~df[\"user_id:token\"].isin(list(choosed_index_del_u))]\n",
    "\n",
    "len(df), len(core_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_df.to_csv(\"./processed/book/book.inter\", sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
